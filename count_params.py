"""
æ¨¡å‹å‚æ•°é‡ç»Ÿè®¡å·¥å…·
æ”¯æŒæŸ¥çœ‹ .pkl / .pth / .onnx æ¨¡å‹çš„å‚æ•°é‡å’Œè¯¦ç»†ä¿¡æ¯
"""
import os
import sys
import argparse
import torch
import onnx


def count_pytorch_params(model_path):
    """ç»Ÿè®¡PyTorchæ¨¡å‹å‚æ•°é‡"""
    print(f"\n{'='*60}")
    print(f"PyTorchæ¨¡å‹å‚æ•°ç»Ÿè®¡: {os.path.basename(model_path)}")
    print(f"{'='*60}")
    
    try:
        # åŠ è½½checkpoint
        checkpoint = torch.load(model_path, map_location='cpu')
        
        # æå–state_dict
        if isinstance(checkpoint, dict):
            if 'state_dict' in checkpoint:
                state_dict = checkpoint['state_dict']
                print(f"âœ… Checkpointç±»å‹: dict (å«state_dict)")
                if 'epoch' in checkpoint:
                    print(f"   è®­ç»ƒepoch: {checkpoint['epoch']}")
                if 'val_psnr' in checkpoint:
                    print(f"   éªŒè¯PSNR: {checkpoint['val_psnr']:.3f}")
            else:
                state_dict = checkpoint
                print(f"âœ… Checkpointç±»å‹: state_dict")
        else:
            state_dict = checkpoint
            print(f"âœ… Checkpointç±»å‹: OrderedDict/å…¶ä»–")
        
        # ç»Ÿè®¡å‚æ•°
        total_params = 0
        trainable_params = 0
        layer_info = []
        
        for name, param in state_dict.items():
            if isinstance(param, torch.Tensor):
                num_params = param.numel()
                total_params += num_params
                
                # å‡è®¾æ‰€æœ‰å‚æ•°éƒ½æ˜¯å¯è®­ç»ƒçš„ï¼ˆstate_dictä¸­æ²¡æœ‰requires_gradä¿¡æ¯ï¼‰
                trainable_params += num_params
                
                layer_info.append({
                    'name': name,
                    'shape': list(param.shape),
                    'params': num_params,
                    'dtype': str(param.dtype)
                })
        
        # æ‰“å°æ€»ä½“ç»Ÿè®¡
        print(f"\n{'='*60}")
        print(f"ğŸ“Š å‚æ•°ç»Ÿè®¡")
        print(f"{'='*60}")
        print(f"æ€»å‚æ•°é‡:        {total_params:>15,} ({total_params/1e6:.2f}M)")
        print(f"å¯è®­ç»ƒå‚æ•°é‡:    {trainable_params:>15,} ({trainable_params/1e6:.2f}M)")
        print(f"å±‚æ•°:            {len(layer_info):>15,}")
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«IWOå‚æ•°
        has_iwo = any('weight1' in info['name'] for info in layer_info)
        if has_iwo:
            iwo_params = sum(info['params'] for info in layer_info if 'weight1' in info['name'])
            print(f"\nâš ï¸  æ£€æµ‹åˆ°IWOå‚æ•°:")
            print(f"   IWOå‚æ•°é‡:    {iwo_params:>15,} ({iwo_params/1e6:.2f}M)")
            print(f"   å æ¯”:         {iwo_params/total_params*100:>14.2f}%")
        
        # æŒ‰å‚æ•°é‡æ’åºï¼Œæ˜¾ç¤ºTop 10
        print(f"\n{'='*60}")
        print(f"ğŸ“‹ å‚æ•°é‡æœ€å¤šçš„10å±‚")
        print(f"{'='*60}")
        layer_info_sorted = sorted(layer_info, key=lambda x: x['params'], reverse=True)
        
        print(f"{'å±‚å':<50} {'å½¢çŠ¶':<25} {'å‚æ•°é‡':>15}")
        print(f"{'-'*60}")
        for i, info in enumerate(layer_info_sorted[:10], 1):
            shape_str = str(info['shape'])
            print(f"{i:2d}. {info['name']:<47} {shape_str:<25} {info['params']:>12,}")
        
        # å¯é€‰ï¼šæ˜¾ç¤ºæ‰€æœ‰å±‚
        show_all = input("\næ˜¯å¦æ˜¾ç¤ºæ‰€æœ‰å±‚çš„è¯¦ç»†ä¿¡æ¯? (y/n): ").strip().lower()
        if show_all == 'y':
            print(f"\n{'='*60}")
            print(f"ğŸ“‹ æ‰€æœ‰å±‚è¯¦ç»†ä¿¡æ¯")
            print(f"{'='*60}")
            print(f"{'å±‚å':<50} {'å½¢çŠ¶':<25} {'å‚æ•°é‡':>15}")
            print(f"{'-'*60}")
            for i, info in enumerate(layer_info, 1):
                shape_str = str(info['shape'])
                print(f"{i:3d}. {info['name']:<47} {shape_str:<25} {info['params']:>12,}")
        
        return total_params
        
    except Exception as e:
        print(f"âŒ åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None


def count_onnx_params(model_path):
    """ç»Ÿè®¡ONNXæ¨¡å‹å‚æ•°é‡"""
    print(f"\n{'='*60}")
    print(f"ONNXæ¨¡å‹å‚æ•°ç»Ÿè®¡: {os.path.basename(model_path)}")
    print(f"{'='*60}")
    
    try:
        model = onnx.load(model_path)
        
        # ç»Ÿè®¡å‚æ•°
        total_params = 0
        initializer_info = []
        
        for initializer in model.graph.initializer:
            # è®¡ç®—å‚æ•°é‡
            shape = [dim for dim in initializer.dims]
            num_params = 1
            for dim in shape:
                num_params *= dim
            
            total_params += num_params
            initializer_info.append({
                'name': initializer.name,
                'shape': shape,
                'params': num_params,
                'dtype': onnx.TensorProto.DataType.Name(initializer.data_type)
            })
        
        # æ‰“å°æ€»ä½“ç»Ÿè®¡
        print(f"\n{'='*60}")
        print(f"ğŸ“Š å‚æ•°ç»Ÿè®¡")
        print(f"{'='*60}")
        print(f"æ€»å‚æ•°é‡:        {total_params:>15,} ({total_params/1e6:.2f}M)")
        print(f"åˆå§‹åŒ–å™¨æ•°é‡:    {len(initializer_info):>15,}")
        
        # è¾“å…¥è¾“å‡ºä¿¡æ¯
        print(f"\n{'='*60}")
        print(f"ğŸ“¥ è¾“å…¥ä¿¡æ¯")
        print(f"{'='*60}")
        for inp in model.graph.input:
            shape = [dim.dim_value if dim.dim_value > 0 else dim.dim_param 
                    for dim in inp.type.tensor_type.shape.dim]
            print(f"   {inp.name}: {shape}")
        
        print(f"\n{'='*60}")
        print(f"ğŸ“¤ è¾“å‡ºä¿¡æ¯")
        print(f"{'='*60}")
        for out in model.graph.output:
            shape = [dim.dim_value if dim.dim_value > 0 else dim.dim_param 
                    for dim in out.type.tensor_type.shape.dim]
            print(f"   {out.name}: {shape}")
        
        # æŒ‰å‚æ•°é‡æ’åºï¼Œæ˜¾ç¤ºTop 10
        print(f"\n{'='*60}")
        print(f"ğŸ“‹ å‚æ•°é‡æœ€å¤šçš„10ä¸ªåˆå§‹åŒ–å™¨")
        print(f"{'='*60}")
        initializer_info_sorted = sorted(initializer_info, key=lambda x: x['params'], reverse=True)
        
        print(f"{'åç§°':<50} {'å½¢çŠ¶':<25} {'å‚æ•°é‡':>15}")
        print(f"{'-'*60}")
        for i, info in enumerate(initializer_info_sorted[:10], 1):
            shape_str = str(info['shape'])
            print(f"{i:2d}. {info['name']:<47} {shape_str:<25} {info['params']:>12,}")
        
        return total_params
        
    except Exception as e:
        print(f"âŒ åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None


def compare_models(model_paths):
    """æ¯”è¾ƒå¤šä¸ªæ¨¡å‹çš„å‚æ•°é‡"""
    print(f"\n{'='*60}")
    print(f"æ¨¡å‹å‚æ•°é‡å¯¹æ¯”")
    print(f"{'='*60}")
    
    results = []
    for path in model_paths:
        if not os.path.isfile(path):
            print(f"âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {path}")
            continue
        
        ext = os.path.splitext(path)[1].lower()
        if ext in ['.pkl', '.pth', '.pt']:
            params = count_pytorch_params(path)
        elif ext == '.onnx':
            params = count_onnx_params(path)
        else:
            print(f"âš ï¸  ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {ext}")
            continue
        
        if params is not None:
            results.append({
                'name': os.path.basename(path),
                'path': path,
                'params': params
            })
    
    # æ‰“å°å¯¹æ¯”è¡¨
    if len(results) > 1:
        print(f"\n{'='*60}")
        print(f"ğŸ“Š å¯¹æ¯”æ€»ç»“")
        print(f"{'='*60}")
        print(f"{'æ¨¡å‹':<40} {'å‚æ•°é‡':>15} {'ç›¸å¯¹æ¯”ä¾‹':>10}")
        print(f"{'-'*60}")
        
        base_params = results[0]['params']
        for i, result in enumerate(results, 1):
            ratio = result['params'] / base_params * 100
            print(f"{i}. {result['name']:<37} {result['params']:>12,} {ratio:>9.1f}%")


def main():
    parser = argparse.ArgumentParser(description='æ¨¡å‹å‚æ•°é‡ç»Ÿè®¡å·¥å…·')
    parser.add_argument('model_path', nargs='+', help='æ¨¡å‹æ–‡ä»¶è·¯å¾„ï¼ˆæ”¯æŒ.pkl/.pth/.onnxï¼‰')
    parser.add_argument('--compare', action='store_true', help='å¯¹æ¯”å¤šä¸ªæ¨¡å‹')
    
    args = parser.parse_args()
    
    if args.compare or len(args.model_path) > 1:
        compare_models(args.model_path)
    else:
        model_path = args.model_path[0]
        
        if not os.path.isfile(model_path):
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
            return
        
        ext = os.path.splitext(model_path)[1].lower()
        
        if ext in ['.pkl', '.pth', '.pt']:
            count_pytorch_params(model_path)
        elif ext == '.onnx':
            count_onnx_params(model_path)
        else:
            print(f"âŒ ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {ext}")
            print(f"   æ”¯æŒçš„æ ¼å¼: .pkl, .pth, .pt, .onnx")


if __name__ == "__main__":
    main()
